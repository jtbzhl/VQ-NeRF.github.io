<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="VQ-NeRF: Neural Reflectance Decomposition and Editing with Vector Quantization">
  <meta name="keywords" content="VQ-NeRF,　NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>VQ-NeRF: Neural Reflectance Decomposition and Editing with Vector Quantization</title>
  
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">VQ-NeRF: Neural Reflectance Decomposition and Editing with Vector Quantization</h1>
          <!-- <h1 class="title is-3">TVCG 2023</h1> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/JiuTongBro">Hongliang Zhong</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://eckertzhang.github.io/">Jingbo Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://liaojing.github.io/html/">Jing Liao</a><sup>1</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>City University of Hong Kong,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2310.11864.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2310.11864"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/-kIHOV28ukk"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/jtbzhl/VQ-NeRF.github.io"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser. -->
<section class="hero teaser">
  <div class="container is-max-desktop">
      <div>
        <img src="./static/images/teaser.png" alt="teaser" class="center">
      </div>
      <div class="content has-text-justified">
          <p>
            We propose VQ-NeRF, which incorporates the VQ mechanism to discretize reflectance decomposition.
            This enables efficient and view-consistent material selection and editing.
          </p>
      </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
  <!-- <div class="container"> -->

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-four-fifths"> -->
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose VQ-NeRF, a two-branch neural network model that incorporates Vector Quantization (VQ) to
            decompose and edit reflectance fields in 3D scenes. Conventional neural reflectance fields use only
            continuous representations to model 3D scenes, despite the fact that objects are typically composed
            of discrete materials in reality. This lack of discretization can result in noisy material decomposition
            and complicated material editing. To address these limitations, our model consists of a continuous branch
            and a discrete branch. The continuous branch follows the conventional pipeline to predict decomposed
            materials, while the discrete branch uses the VQ mechanism to quantize continuous materials into individual
            ones. By discretizing the materials, our model can reduce noise in the decomposition process and generate a
            segmentation map of discrete materials. Specific materials can be easily selected for further editing by
            clicking on the corresponding area of the segmentation outcomes. Additionally, we propose a dropout-based
            VQ codeword ranking strategy to predict the number of materials in a scene, which reduces redundancy in the
            material segmentation process. To improve usability, we also develop an interactive interface to further
            assist material editing. We evaluate our model on both computer-generated and real-world scenes,
            demonstrating its superior performance. To the best of our knowledge, our model is the first to enable
            discrete material editing in 3D scenes.
          </p>
        </div>
      </div>
    </div>

    <!-- Pipeline. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <br />
        <h2 class="title is-3">Pipeline</h2>
        
        <div>
          <img src="./static/images/pipeline.png" alt="method" class="center">
        </div>
        <div class="content has-text-justified">
          <p>
            Overview of our VQ-NeRF. We first take multi-view posed images as inputs and use a NeRF model (gray part)
            to reconstruct the scene geometry. Next, we apply a two-branch network for reflectance decomposition and
            material discretization. The continuous branch (green part) predicts the decomposed BRDF attributes,
            including diffuse, specular, and roughness, while the discrete branch (red part) uses the VQ mechanism to
            discretize reflectance factors. After optimization, a material map is generated, which enables us to easily
            select specific materials for editing.
          </p>
        </div>

      </div>
    </div>


    <!-- Results. -->
      <div class="container is-max-desktop">
        <br />
        <h2 class="title is-3"><center>Results</center></h2>

        <h3 class="title is-5" style="text-align:left">Reconstruction & Relighting</h3>
        <!-- line 1 -->
        <table style="width:100%">
          <tr>
              <td><center>
                <video poster="" autoplay controls muted loop playsinline height="90%" width="90%">
                  <source src="./static/video/relit.mp4"
                          type="video/mp4">
                </video>
              </center></td>
          </tr>
        </table>
        <table style="width:100%">
          <tr>
            <td style="width: 50%;"><center><p>In comparison with: NVDIFFRECMC [1], NVDIFFREC [2], and NeRFactor [3]</p></center></td>
          </tr>
        </table>
        <br />
        <table style="width:100%">
          <tr>
            <td style="width: 50%;"><p>[1] Shape, Light, and Material Decomposition from Images using Monte Carlo Rendering and Denoising. NeurIPS 2022.</p></td>
          </tr>
          <tr>
            <td style="width: 50%;"><p>[2] Extracting Triangular 3D Models, Materials, and Lighting From Images. CVPR 2022.</p></td>
          </tr>
          <tr>
            <td style="width: 50%;"><p>[3] NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination. TOG 2021.</p></td>
          </tr>
        </table>

        <br />
        <h3 class="title is-5" style="text-align:left">Material Editing</h3>
        <!-- line 1 -->
        <table style="width:100%">
          <tr>
              <td><center>
                <video poster="" autoplay controls muted loop playsinline height="90%" width="90%">
                  <source src="./static/video/mat_edit.mp4"
                          type="video/mp4">
                </video>
              </center></td>
          </tr>
        </table>

        <br />
        <h3 class="title is-5" style="text-align:left">Material & Illumination Editing</h3>
        <!-- line 1 -->
        <table style="width:100%">
          <tr>
              <td><center>
                <video poster="" autoplay controls muted loop playsinline height="90%" width="90%">
                  <source src="./static/video/joint_edit.mp4"
                          type="video/mp4">
                </video>
              </center></td>
          </tr>
        </table>
      </div>


    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <br />
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/-kIHOV28ukk" title="YouTube video player"
                  frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;
                  picture-in-picture; web-share" allowfullscreen></iframe>

        </div>
      </div>
    </div>

  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <!-- <pre><code>@article{zhang2022fdnerf,
      title={FDNeRF: Few-shot Dynamic Neural Radiance Fields for Face Reconstruction and Expression Editing},
      author={Zhang, Jingbo and Li, Xiaoyu and Wan, Ziyu and Wang, Can and Liao, Jing},
      journal={arXiv preprint arXiv:2208.05751},
      year={2022}
    }</code></pre> -->
  </div>
</section>


<footer class="footer">
  <div class="container">

    <div class="content has-text-centered">
      <a class="icon-link"
        href="https://arxiv.org/pdf/2208.05751.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" 
        href="https://github.com/FDNeRF/FDNeRF" 
        class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.

            The <a href="https://github.com/nerfies/nerfies.github.io">source code</a> for the website 
            was taken from Nerfies. We appreciate the authors sharing the templates with us.
          </p>
        </div>
      </div>
    </div>

  </div>
</footer>

</body>
</html>
